# An Explainable GNN-Based Framework for Negative Knowledge Discovery Using Scientific Knowledge Graphs

---

## 1. Introduction

### 1.1 Background
Scientific research is growing at an unprecedented pace â€” over 3 million papers are published annually. Yet, critical connections between research concepts often remain undiscovered, not because they lack merit, but because no researcher has investigated them. These missing connections, termed **"Negative Knowledge,"** represent research gaps that, if identified, could accelerate scientific breakthroughs.

Traditional methods of identifying research gaps rely on manual literature surveys â€” a process that is time-consuming, biased toward a researcher's existing knowledge, and fundamentally limited by the volume of published work a single person can read.

### 1.2 Problem Statement
Given a large corpus of scientific papers, can we automatically construct a knowledge graph of research concepts and use Graph Neural Networks to predict which connections (edges) are missing â€” thereby discovering research gaps that scientists have overlooked?

### 1.3 Objective
To develop an **explainable, domain-agnostic framework** that:
1. Automatically collects research papers from multiple online sources
2. Extracts biomedical entities using NLP
3. Constructs a scientific knowledge graph
4. Trains a Graph Neural Network for link prediction
5. Identifies and ranks potential research gaps with confidence scores
6. Presents results through an interactive, transparent 3D visualization

### 1.4 Scope
- **Current demonstration:** Mental Health domain (depression, anxiety, PTSD, therapies, etc.)
- **Framework design:** Domain-agnostic â€” configurable for Diabetes, Cancer, or any scientific field via `config.yaml`

### 1.5 Significance
- **For Researchers:** Reduces hypothesis generation time from months to seconds
- **For Funding Bodies:** Provides data-driven prioritization of understudied topics
- **For AI Ethics:** Full model transparency built into the output â€” architecture, metrics, and methodology are visible

---

## 2. Literature Survey

### 2.1 Knowledge Graphs in Biomedical Research
Knowledge graphs (KGs) represent entities as nodes and relationships as edges. In biomedical research, KGs like UMLS, DrugBank, and DisGeNET have been used to organize structured medical knowledge. However, these are manually curated and cannot scale with the rate of new publications.

### 2.2 Graph Neural Networks (GNNs)
GNNs extend deep learning to graph-structured data. Key architectures include:
- **GCN (Graph Convolutional Network)** â€” Kipf & Welling, 2017: Aggregates neighbor features via spectral convolution
- **GAT (Graph Attention Network)** â€” VeliÄkoviÄ‡ et al., 2018: Learns attention weights over neighbors
- **GraphSAGE** â€” Hamilton et al., 2017: Samples and aggregates neighbor features inductively

### 2.3 Link Prediction
Link prediction aims to predict missing edges in a graph. Methods include:
- **Heuristic-based:** Common Neighbors, Jaccard Coefficient, Adamic-Adar Index
- **Embedding-based:** Node2Vec (Grover & Leskovec, 2016), DeepWalk (Perozzi et al., 2014)
- **GNN-based:** GCN + dot-product decoder, VGAE (Kipf & Welling, 2016)

### 2.4 Research Gap Identification
Existing gap identification tools are limited to keyword frequency analysis or citation network clustering. No prior work uses GNN-based link prediction specifically as a research gap discovery mechanism with explainable AI transparency.

### 2.5 Our Contribution
We bridge these areas by building an end-to-end framework that combines NLP-based entity extraction, automated knowledge graph construction, GNN link prediction, and transparent visualization â€” all in a single, reproducible pipeline.

---

## 3. System Architecture

### 3.1 High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA COLLECTION LAYER                     â”‚
â”‚  Semantic Scholar API  â”‚  PubMed API  â”‚  arXiv API          â”‚
â”‚        (JSON)          â”‚   (XML)      â”‚  (Atom XML)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NLP PROCESSING LAYER                      â”‚
â”‚  Entity Extraction: scispaCy (en_core_sci_sm, bc5cdr)       â”‚
â”‚  Entity Classification: Keyword-based categorization        â”‚
â”‚  Relation Extraction: Sentence-level co-occurrence          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  KNOWLEDGE GRAPH LAYER                       â”‚
â”‚  NetworkX Graph: 659 core nodes, 4,856 edges                â”‚
â”‚  Structural Features: Node2Vec (128-dimensional)            â”‚
â”‚  Semantic Features: SciBERT (768-dimensional)               â”‚
â”‚  Combined Node Vector: 896-dimensional                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   GNN PREDICTION LAYER                       â”‚
â”‚  Encoder: 2-layer GCN (896â†’128â†’64)                          â”‚
â”‚  Decoder: Bilinear Matrix + 3-layer MLP                     â”‚
â”‚  Training: Multi-seed (3 initializations), Adam, BCE Loss   â”‚
â”‚  Result: Test ROC-AUC = 74.1% (Validation = 76.8%)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  VISUALIZATION LAYER                         â”‚
â”‚  Plotly 3D Interactive Graph                                â”‚
â”‚  AI Transparency Panels                                     â”‚
â”‚  Top 20 Research Gap Predictions                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Technology Stack

| Component | Technology | Purpose |
|---|---|---|
| Language | Python 3.11 | Core programming language |
| Deep Learning | PyTorch 2.0+, PyTorch Geometric | GNN model training |
| NLP | spaCy, scispaCy | Entity extraction from abstracts |
| Graph Processing | NetworkX | Knowledge graph construction |
| Embeddings | Node2Vec + SciBERT | Hybrid feature generation |
| Database | SQLite | Structured data storage |
| Visualization | Plotly | 3D interactive graph |
| Data Collection | Requests | API communication |

### 3.3 Database Schema

**Table: `papers`** â€” Stores fetched research papers

| Column | Type | Description |
|---|---|---|
| paper_id | TEXT (PK) | Unique identifier from source |
| title | TEXT | Paper title |
| abstract | TEXT | Full abstract text |
| year | INTEGER | Publication year |
| authors | TEXT | Comma-separated author names |
| venue | TEXT | Journal or conference |
| source | TEXT | "Semantic Scholar" / "PubMed" / "arXiv" |

**Table: `entities`** â€” Stores extracted NLP entities

| Column | Type | Description |
|---|---|---|
| id | INTEGER (PK) | Auto-incrementing ID |
| paper_id | TEXT (FK) | Links to papers table |
| entity | TEXT | Extracted entity (lowercased) |
| type | TEXT | "biomedical_term" or "disease_or_drug" |
| source | TEXT | NLP model ("sci_sm" or "bc5cdr") |
| category | TEXT | "disorder" / "therapy" / "risk_factor" / "outcome" / "population" |

**Table: `relations`** â€” Stores entity co-occurrence relations

| Column | Type | Description |
|---|---|---|
| id | INTEGER (PK) | Auto-incrementing ID |
| paper_id | TEXT (FK) | Links to papers table |
| head | TEXT | Entity 1 |
| relation | TEXT | "related_to" |
| tail | TEXT | Entity 2 |

---

## 4. Methodology

### 4.1 Data Collection
Research papers are fetched from three academic APIs:

**Semantic Scholar** â€” RESTful API returning JSON. We aggressively query 20 mental health search terms, fetching hundreds of papers per term.

**PubMed (NIH Entrez)** â€” A two-step process: (1) search for PubMed IDs via `esearch.fcgi` (JSON), (2) fetch paper details via `efetch.fcgi` (XML). We parse `<ArticleTitle>`, `<AbstractText>`, `<PubDate>`, and `<Author>` elements. 

**Total collected:** Expanded dataset of **872 papers** capturing a dense, interconnected web.

### 4.2 NLP Entity Extraction
Two pretrained spaCy/scispaCy models run on every abstract:

- **`en_core_sci_sm`** â€” A general scientific NER model trained on biomedical corpora. Extracts broad biomedical terms (disorders, biological processes, therapies).
- **`en_ner_bc5cdr_md`** â€” Trained on the BioCreative V CDR corpus (14,000+ annotated abstracts). Specializes in disease and drug/chemical entity recognition.

Entities are lowercased, aggressively deduplicated, and stored in the `entities` table (**~46,000 entities extracted**).

### 4.3 Entity Classification
Entities are categorized into 5 semantic classes using keyword matching:

| Category | Example Keywords |
|---|---|
| Disorder | depression, anxiety, ptsd, bipolar, ocd, schizophrenia |
| Therapy | therapy, cbt, dbt, counseling, ssri, mindfulness |
| Risk Factor | trauma, abuse, stress, insomnia, loneliness, poverty |
| Outcome | suicide, relapse, recovery, quality of life, mortality |
| Population | adolescent, child, women, veteran, elderly |

Entities that don't match any category are excluded from the graph.

### 4.4 Relation Extraction
Relations are identified through **sentence-level co-occurrence**: if two categorized entities appear in the same sentence of an abstract, they are linked with a `"related_to"` relation. We use spaCy's `en_core_web_sm` for sentence boundary detection.

### 4.5 Knowledge Graph Construction
A NetworkX undirected graph is built from the database:
- **Nodes** = All unique, deduplicated entities with a non-null category (659 core nodes)
- **Edges** = All unique relations excluding self-loops (4,856 edges)

### 4.6 Node Embedding (Hybrid Topology + Semantic)
Because knowledge graphs often suffer from structural sparsity, we use a hybrid **896-dimensional** feature vector:

1. **Topology (Node2Vec)**: 128-dimensional embedding from biased random walks mapping the exact structure.
2. **Semantic Meaning (SciBERT)**: 768-dimensional language embedding from `allenai/scibert_scivocab_uncased`, capturing deep medical meaning even for isolated nodes.

### 4.7 GCN Model Architecture

**Encoder (Dimensionality Reduction):**
```
Input Layer:        X âˆˆ â„^(659 Ã— 896)    â† Node2Vec + SciBERT
                          â”‚
Layer 1:           GCNConv(896 â†’ 128)    â† Message passing + BatchNorm
                          â”‚
Activation:            ReLU               â† Non-linearity + 45% Dropout
                          â”‚
Layer 2:           GCNConv(128 â†’ 64)     â† Compression to 64D
```

**Bilinear Hybrid Decoder:**
Unlike a simple dot-product, we use a learned metric to predict probability:
1. **Bilinear Matrix ($W$)**: Learns asymmetrical scaling between dimensions (`z_u^T * W * z_v`)
2. **MLP Fusion**: Concatenates `[z_u | z_v | z_u * z_v]` and passes through a 3-layer neural net.
3. The scores are summed and passed through a Sigmoid activation.

### 4.8 Training Procedure

| Parameter | Value |
|---|---|
| Epochs | 400 |
| Optimizer | Adam (lr=0.005) |
| Scheduler | ReduceLROnPlateau |
| Loss Function | Binary Cross-Entropy with Logits |
| Initialization | 3 Random Seeds (Selects Best Validation AUC) |

**Training Strategy:** 10% of edges are removed entirely as a Test Set. The model sees 80% for training and 10% for validation. Early stopping monitors the validation set to prevent overfitting on the sparse graph.

### 4.9 Evaluation Metric
**ROC-AUC (Receiver Operating Characteristic - Area Under the Curve):**
- Measures the model's ability to rank real edges higher than non-edges.
- This is a strict transductive link prediction metric on fully hidden test edges.

---

## 5. Results

### 5.1 Model Performance

| Metric | Value |
|---|---|
| Best Validation ROC-AUC | **76.8%** |
| Final Test ROC-AUC | **74.1%** |
| Real-World Implication | Identifies true research gaps correctly ~74% of the time |

### 5.2 Knowledge Graph Statistics

| Metric | Value |
|---|---|
| Total papers fetched | 872 |
| Total entities extracted | ~46,000 |
| Deduplicated Core Nodes | 659 |
| Deduplicated Core Edges | 4,856 |
| Feature Dimensions | 896 (Hybrid) |

### 5.3 Top AI Predicted Research Gaps

| Rank | Concept 1 | Concept 2 | AI Confidence |
|---|---|---|---|
| 1 | Trauma-focused CBT | Depression | 82.9% |
| 2 | Loneliness | Beck Anxiety Inventory | 82.6% |
| 3 | Advanced Treatments | Bipolar Disorder | 81.6% |
| 4 | Monotherapy | Anxiety | 81.4% |
| 5 | Depression | Quality of Sleep | 80.5% |

### 5.4 Visualization
The output is an interactive 3D graph (`graph_credible_ai.html`) featuring:
- 659 nodes color-coded by category (blue-cyan gradient, size proportional to degree)
- 2,428 existing edges (grey)
- Top 20 predicted gaps (red, highlighted)
- Three AI transparency panels: Model Details, Top 20 Predictions, Methodology

---

## 6. Explainability (XAI)

The framework incorporates explainability through:

1. **Model Transparency Panel** â€” Displays exact architecture (GCN layers, dimensions), training hyperparameters, and the ROC-AUC score directly in the visualization
2. **Prediction Confidence Scores** â€” Each predicted gap shows its exact probability score, allowing researchers to assess reliability
3. **Methodology Panel** â€” The 5-step pipeline is explained in the visualization, making the process reproducible
4. **Category-based Color Coding** â€” Nodes are colored by semantic category, making it intuitive to understand what types of concepts are being connected
5. **Disclaimers** â€” The visualization includes responsible AI disclaimers, noting that predictions are suggestions for investigation, not verified facts

---

## 7. Advantages

1. **Automated Discovery** â€” Replaces months of manual literature review with seconds of computation
2. **Domain-Agnostic** â€” Framework works for any scientific domain via config-driven architecture
3. **Multi-Source Data** â€” Combines 3 academic data sources for comprehensive coverage
4. **Explainable AI** â€” Full transparency panels built into the output, not a black-box
5. **Reproducible** â€” Entire pipeline is scripted and produces consistent results from the same data
6. **Portable** â€” SQLite database (single file) and self-contained HTML visualization require no server
7. **Scalable Architecture** â€” Pipeline can be extended to handle more sources and larger graphs

---

## 8. Limitations

1. **No formal train/val/test split** â€” Currently evaluating on all edges; future versions will implement proper data splitting
2. **Negation blindness** â€” "CBT is ineffective for PTSD" still creates a CBT-PTSD edge; no negation detection in the NLP pipeline
3. **English-only** â€” Misses research published in other languages
4. **Batch processing** â€” Pipeline is offline; no real-time updates when new papers are published
5. **Undirected graph** â€” Loses causal directionality; "A causes B" is treated the same as "B is associated with A"
6. **Single domain tested** â€” Only Mental Health is fully demonstrated; Diabetes and Cancer configs exist but are not yet executed

---

## 9. Future Scope

### 9.1 Multi-Domain Support with User Interface
The `config.yaml` already defines domain configurations for **Diabetes** and **Cancer**. In a future version:
- A web-based UI will allow researchers to **select or type any domain**
- The system will automatically load the appropriate search terms, entity categories, and color schemes
- The entire pipeline (fetch â†’ extract â†’ graph â†’ train â†’ predict â†’ visualize) will execute end-to-end **without code changes**

### 9.2 Directed Causal Knowledge Graph
Replace co-occurrence-based relations with **causal relation extraction** using dependency parsing or transformer-based relation extraction models. This converts the undirected graph into a directed graph, enabling causal gap analysis (e.g., "What causes X that we haven't studied?").

### 9.3 Real-Time Paper Ingestion
Implement a WebSocket-based pipeline that automatically detects new publications on PubMed/arXiv, triggers entity extraction, updates the knowledge graph incrementally, and re-runs link prediction.

### 9.4 Cross-Domain Fusion
Build a **unified knowledge graph** spanning Mental Health + Diabetes + Cancer to discover **inter-disciplinary research gaps** â€” connections between domains that no single-domain researcher would identify.

### 9.5 Enhanced NLP with LLMs
Replace keyword-based entity classification with **LLM-powered entity typing** (e.g., using GPT/BERT) for more accurate and nuanced categorization. Add negation detection to avoid false-positive relations.

### 9.6 Advanced GNN Architectures
Experiment with:
- **GAT (Graph Attention Networks)** for learned importance weighting of neighbors
- **VGAE (Variational Graph Auto-Encoders)** for probabilistic link prediction
- **GraphSAGE** for inductive learning on unseen nodes

---

## 10. Conclusion

We presented an **explainable GNN-based framework** for discovering negative knowledge in scientific literature. The framework automatically collects research papers from Semantic Scholar, PubMed, and arXiv; extracts biomedical entities using scispaCy; constructs a knowledge graph of 659 core concepts and 4,856 connections using a hybrid 896-dimensional embedding (Node2Vec + SciBERT); trains a Bilinear Hybrid GNN Decoder achieving a robust, real-world **74.1% Test ROC-AUC**; and presents the top predicted research gaps in an interactive 3D visualization with full AI transparency.

The framework is designed to be **domain-agnostic** â€” while currently demonstrated on Mental Health, the same architecture generalizes to any scientific field through configuration. By automating the discovery of research gaps (such as the connection between Trauma-focused CBT and Depression), this work has the potential to redirect scientific effort toward the most impactful understudied questions in an explainable and reliable way.

---

## 11. References

1. Kipf, T.N. and Welling, M. (2017). "Semi-Supervised Classification with Graph Convolutional Networks." *ICLR 2017.*
2. Grover, A. and Leskovec, J. (2016). "Node2Vec: Scalable Feature Learning for Networks." *KDD 2016.*
3. VeliÄkoviÄ‡, P. et al. (2018). "Graph Attention Networks." *ICLR 2018.*
4. Hamilton, W.L. et al. (2017). "Inductive Representation Learning on Large Graphs." *NeurIPS 2017.*
5. Perozzi, B. et al. (2014). "DeepWalk: Online Learning of Social Representations." *KDD 2014.*
6. Kipf, T.N. and Welling, M. (2016). "Variational Graph Auto-Encoders." *NeurIPS Workshop 2016.*
7. Neumann, M. et al. (2019). "ScispaCy: Fast and Robust Models for Biomedical Natural Language Processing." *BioNLP 2019.*
8. Li, J. et al. (2016). "BioCreative V CDR task corpus: a resource for chemical disease relation extraction." *Database, 2016.*
9. Semantic Scholar API Documentation. Allen Institute for AI. https://api.semanticscholar.org/
10. PubMed Entrez Programming Utilities. NCBI, National Library of Medicine. https://www.ncbi.nlm.nih.gov/books/NBK25501/

---

## 12. Appendix

### A. Search Terms Used (Mental Health Domain)
1. "depression mental health"
2. "anxiety disorder treatment"
3. "PTSD therapy"
4. "suicidal ideation risk"
5. "cognitive behavioral therapy"
6. "dialectical behavior therapy"
7. "bipolar disorder treatment"
8. "mindfulness therapy"
9. "trauma mental health"
10. "loneliness depression"

### B. Entity Category Keywords

| Category | Keywords |
|---|---|
| Disorder | depression, anxiety, ptsd, bipolar, panic, ocd, schizophrenia, phobia, adhd, autism |
| Therapy | therapy, cbt, dbt, treatment, counseling, psychotherapy, mindfulness, ssri, antidepressant, medication |
| Risk Factor | trauma, abuse, stress, insomnia, sleep, loneliness, poverty, bullying, neglect |
| Outcome | suicide, relapse, recovery, self harm, quality of life, mortality, ideation, remission |
| Population | adolescent, child, teen, student, women, men, adult, elderly, veteran |

### C. Pre-Configured Domains in `config.yaml`

| Domain | Status | Example Search Terms |
|---|---|---|
| Mental Health | âœ… Active | depression, anxiety, PTSD, CBT |
| Diabetes | ğŸ”œ Ready | insulin resistance, diabetic neuropathy |
| Cancer | ğŸ”œ Ready | breast cancer, immunotherapy, tumor biomarkers |

### D. Output Files

| File | Format | Contents |
|---|---|---|
| `mindgap.db` | SQLite | Papers, entities, relations |
| `mental_health_graph.pkl` | Pickle | NetworkX knowledge graph |
| `node_embeddings.wv` | Gensim WV | 659 Ã— 64D Node2Vec embeddings |
| `pyg_graph.pt` | PyTorch | Graph data for GNN training |
| `gnn_model.pt` | PyTorch | Trained GCN model weights |
| `graph_credible_ai.html` | HTML | Interactive 3D visualization |
